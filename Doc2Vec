spam_vector = numpy.zeros((1500,100))
ham_vector = numpy.zeros((3000,100))
test_vector = numpy.zeros((100,100))
scount = 0;

for root, dirs, files in os.walk('./SpamTraining/'):
  
  for file in files:   
    #print(file)          
    train_data = read_spammail(file)
     a = len(train_data)
          #print train_data
          #log.info('source load')
          sources = {'./SpamTraining/'+file:'TEST'}
          #log.info('TaggedDocument')
          sentences = TaggedLineSentence(sources)
          #log.info('D2V')
          model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=7)
          model.build_vocab(sentences.to_array())
          #log.info('Epoch')
          for epoch in range(10): 
               # log.info('EPOCH: {}'.format(epoch))
               model.train(sentences.sentences_perm())
          #log.info('Model Save')
          model.save('./imdb.d2v')
          model = Doc2Vec.load('./imdb.d2v')
          temp_arrays = numpy.zeros((1, 100))
          train_arrays = numpy.zeros((1,100))
          
          for i in range(a):
              prefix_test = 'TEST_' + str(i)
              temp_arrays[0] = model.docvecs[prefix_test]
              train_arrays = train_arrays + temp_arrays
          #print train_arrays
          spam_vector[scount] = train_arrays
          scount = scount +1

print spam_vector
hcount = 0;
for root, dirs, files in os.walk('./HamTraining/'):     
  for file in files:
    #print(file)
    train_data = read_hammail(file) 
    
    a = len(train_data)
          #print train_data
          #log.info('source load')
          sources = {'./HamTraining/'+file:'TEST'}
          #log.info('TaggedDocument')
          sentences = TaggedLineSentence(sources)
          #log.info('D2V')
          model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=7)
          model.build_vocab(sentences.to_array())
          #log.info('Epoch')
          for epoch in range(10):
               # log.info('EPOCH: {}'.format(epoch))
               model.train(sentences.sentences_perm())
          #log.info('Model Save')
          model.save('./imdb.d2v')
          model = Doc2Vec.load('./imdb.d2v')
          temp_arrays = numpy.zeros((1, 100))
          train_arrays = numpy.zeros((1,100))
          
          for i in range(a):
              prefix_test = 'TEST_' + str(i)
              temp_arrays[0] = model.docvecs[prefix_test]
              train_arrays = train_arrays + temp_arrays
          ham_vector[hcount] = train_arrays
          hcount = hcount +1;
print ham_vector
tcount = 0;
 for root, dirs, files in os.walk('./Test/'):
    
   for file in files:
  #print(file)
          train_data = read_testmail(file)
          
          a = len(train_data)
          #print train_data
          #log.info('source load')
          sources = {'./Test/'+file:'TEST'}
          #log.info('TaggedDocument')
          sentences = TaggedLineSentence(sources)
          #log.info('D2V')
          model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=7)
          model.build_vocab(sentences.to_array())
          #log.info('Epoch')
          for epoch in range(10):
               # log.info('EPOCH: {}'.format(epoch))
               model.train(sentences.sentences_perm())
          #log.info('Model Save')
          model.save('./imdb.d2v')
          model = Doc2Vec.load('./imdb.d2v')
          temp_arrays = numpy.zeros((1, 100))
          train_arrays = numpy.zeros((1,100))
          
          for i in range(a):
              prefix_test = 'TEST_' + str(i)
              temp_arrays[0] = model.docvecs[prefix_test]
              train_arrays = train_arrays + temp_arrays
      
          test_vector[tcount] = train_arrays
          tcount = tcount +1
         
